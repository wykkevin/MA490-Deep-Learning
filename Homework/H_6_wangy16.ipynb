{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfdx(f,x):\n",
    "    eps = 10**(-5)\n",
    "    y = f(x)\n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "    dfdx = np.zeros((m,n))\n",
    "    for k in range(n):\n",
    "        dx = np.zeros(n)\n",
    "        dx[k] = eps\n",
    "        fp = f(x + dx)\n",
    "        fm = f(x - dx)\n",
    "        dfdx[:,k] = (fp - fm)/(2*eps)\n",
    "    return dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = np.array([np.sqrt(x[0]*x[1]),x[1]**2+x[0]*np.exp(x[1])])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.5       ]\n",
      " [2.71828183 4.71828183]]\n"
     ]
    }
   ],
   "source": [
    "dydx = dfdx(f,x)\n",
    "print(dydx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsmax(x):\n",
    "    k = x.max()\n",
    "    e = np.exp(x-k)\n",
    "    p = e/e.sum()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dydfsmax(x):\n",
    "    k = x.max()\n",
    "    e = np.exp(x-k)\n",
    "    p = e/e.sum()\n",
    "    return np.outer(p,p)-np.diag(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16621656, -0.04355669, -0.03637662, -0.03610804, -0.05017522],\n",
       "       [-0.04355669,  0.16407752, -0.03574225, -0.03547835, -0.04930022],\n",
       "       [-0.03637662, -0.03574225,  0.14292218, -0.02962995, -0.04117336],\n",
       "       [-0.03610804, -0.03547835, -0.02962995,  0.1420857 , -0.04086936],\n",
       "       [-0.05017522, -0.04930022, -0.04117336, -0.04086936,  0.18151816]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dydx = dfdx(fsmax,x)\n",
    "dydx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16621656,  0.04355669,  0.03637662,  0.03610804,  0.05017522],\n",
       "       [ 0.04355669, -0.16407752,  0.03574225,  0.03547835,  0.04930022],\n",
       "       [ 0.03637662,  0.03574225, -0.14292218,  0.02962995,  0.04117336],\n",
       "       [ 0.03610804,  0.03547835,  0.02962995, -0.1420857 ,  0.04086936],\n",
       "       [ 0.05017522,  0.04930022,  0.04117336,  0.04086936, -0.18151816]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dydx2 = dydfsmax(x)\n",
    "dydx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Boston_home_prices.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('medv',axis=1)\n",
    "target = df['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.326673e-17</td>\n",
       "      <td>3.466704e-16</td>\n",
       "      <td>-3.016965e-15</td>\n",
       "      <td>3.999875e-16</td>\n",
       "      <td>3.507405e-15</td>\n",
       "      <td>-1.249418e-14</td>\n",
       "      <td>-1.158274e-15</td>\n",
       "      <td>7.308603e-16</td>\n",
       "      <td>-1.068535e-15</td>\n",
       "      <td>6.534079e-16</td>\n",
       "      <td>-1.084420e-14</td>\n",
       "      <td>8.117354e-15</td>\n",
       "      <td>-6.494585e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.193669e-01</td>\n",
       "      <td>-4.872402e-01</td>\n",
       "      <td>-1.556302e+00</td>\n",
       "      <td>-2.723291e-01</td>\n",
       "      <td>-1.464433e+00</td>\n",
       "      <td>-3.876413e+00</td>\n",
       "      <td>-2.333128e+00</td>\n",
       "      <td>-1.265817e+00</td>\n",
       "      <td>-9.818712e-01</td>\n",
       "      <td>-1.312691e+00</td>\n",
       "      <td>-2.704703e+00</td>\n",
       "      <td>-3.903331e+00</td>\n",
       "      <td>-1.529613e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.105633e-01</td>\n",
       "      <td>-4.872402e-01</td>\n",
       "      <td>-8.668328e-01</td>\n",
       "      <td>-2.723291e-01</td>\n",
       "      <td>-9.121262e-01</td>\n",
       "      <td>-5.680681e-01</td>\n",
       "      <td>-8.366200e-01</td>\n",
       "      <td>-8.048913e-01</td>\n",
       "      <td>-6.373311e-01</td>\n",
       "      <td>-7.668172e-01</td>\n",
       "      <td>-4.875567e-01</td>\n",
       "      <td>2.048688e-01</td>\n",
       "      <td>-7.986296e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.902803e-01</td>\n",
       "      <td>-4.872402e-01</td>\n",
       "      <td>-2.108898e-01</td>\n",
       "      <td>-2.723291e-01</td>\n",
       "      <td>-1.440749e-01</td>\n",
       "      <td>-1.083583e-01</td>\n",
       "      <td>3.170678e-01</td>\n",
       "      <td>-2.790473e-01</td>\n",
       "      <td>-5.224844e-01</td>\n",
       "      <td>-4.642132e-01</td>\n",
       "      <td>2.745872e-01</td>\n",
       "      <td>3.808097e-01</td>\n",
       "      <td>-1.810744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.389247e-03</td>\n",
       "      <td>4.872402e-02</td>\n",
       "      <td>1.014995e+00</td>\n",
       "      <td>-2.723291e-01</td>\n",
       "      <td>5.980871e-01</td>\n",
       "      <td>4.822906e-01</td>\n",
       "      <td>9.059016e-01</td>\n",
       "      <td>6.617161e-01</td>\n",
       "      <td>1.659603e+00</td>\n",
       "      <td>1.529413e+00</td>\n",
       "      <td>8.057784e-01</td>\n",
       "      <td>4.332223e-01</td>\n",
       "      <td>6.024226e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.924110e+00</td>\n",
       "      <td>3.800473e+00</td>\n",
       "      <td>2.420170e+00</td>\n",
       "      <td>3.664771e+00</td>\n",
       "      <td>2.729645e+00</td>\n",
       "      <td>3.551530e+00</td>\n",
       "      <td>1.116390e+00</td>\n",
       "      <td>3.956602e+00</td>\n",
       "      <td>1.659603e+00</td>\n",
       "      <td>1.796416e+00</td>\n",
       "      <td>1.637208e+00</td>\n",
       "      <td>4.406159e-01</td>\n",
       "      <td>3.545262e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               crim            zn         indus          chas           nox  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean   8.326673e-17  3.466704e-16 -3.016965e-15  3.999875e-16  3.507405e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -4.193669e-01 -4.872402e-01 -1.556302e+00 -2.723291e-01 -1.464433e+00   \n",
       "25%   -4.105633e-01 -4.872402e-01 -8.668328e-01 -2.723291e-01 -9.121262e-01   \n",
       "50%   -3.902803e-01 -4.872402e-01 -2.108898e-01 -2.723291e-01 -1.440749e-01   \n",
       "75%    7.389247e-03  4.872402e-02  1.014995e+00 -2.723291e-01  5.980871e-01   \n",
       "max    9.924110e+00  3.800473e+00  2.420170e+00  3.664771e+00  2.729645e+00   \n",
       "\n",
       "                 rm           age           dis           rad           tax  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -1.249418e-14 -1.158274e-15  7.308603e-16 -1.068535e-15  6.534079e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -3.876413e+00 -2.333128e+00 -1.265817e+00 -9.818712e-01 -1.312691e+00   \n",
       "25%   -5.680681e-01 -8.366200e-01 -8.048913e-01 -6.373311e-01 -7.668172e-01   \n",
       "50%   -1.083583e-01  3.170678e-01 -2.790473e-01 -5.224844e-01 -4.642132e-01   \n",
       "75%    4.822906e-01  9.059016e-01  6.617161e-01  1.659603e+00  1.529413e+00   \n",
       "max    3.551530e+00  1.116390e+00  3.956602e+00  1.659603e+00  1.796416e+00   \n",
       "\n",
       "            ptratio         black         lstat  \n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  \n",
       "mean  -1.084420e-14  8.117354e-15 -6.494585e-16  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -2.704703e+00 -3.903331e+00 -1.529613e+00  \n",
       "25%   -4.875567e-01  2.048688e-01 -7.986296e-01  \n",
       "50%    2.745872e-01  3.808097e-01 -1.810744e-01  \n",
       "75%    8.057784e-01  4.332223e-01  6.024226e-01  \n",
       "max    1.637208e+00  4.406159e-01  3.545262e+00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = features.mean()\n",
    "sd = features.std()\n",
    "features_s = (features - mu)/sd\n",
    "features_s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features_s.values\n",
    "y = target.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  4.680019641624429  baseline RMSE =  9.188011545278203\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1,input_shape=(13,)))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='Adam')\n",
    "\n",
    "hist = model.fit(X,y,epochs=5000,verbose=0)\n",
    "\n",
    "mse = hist.history['loss'][-1]\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE = ' ,rmse, ' baseline RMSE = ',y.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notMNIST = np.load('MNIST_train_100.npz')\n",
    "\n",
    "images = notMNIST['train_images']\n",
    "labels = notMNIST['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = images.reshape(100,28*28)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(labels).values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    58\n",
       "4    42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = 58/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 4.6009 - acc: 0.4625 - val_loss: 4.3522 - val_acc: 0.3500\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 4.2119 - acc: 0.5500 - val_loss: 4.0153 - val_acc: 0.4000\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 236us/step - loss: 3.8477 - acc: 0.5750 - val_loss: 3.7036 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 3.5177 - acc: 0.5750 - val_loss: 3.4177 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 199us/step - loss: 3.2095 - acc: 0.5750 - val_loss: 3.1427 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 2.9302 - acc: 0.6375 - val_loss: 2.8829 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 185us/step - loss: 2.6714 - acc: 0.6500 - val_loss: 2.6399 - val_acc: 0.4500\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 212us/step - loss: 2.4356 - acc: 0.6500 - val_loss: 2.4224 - val_acc: 0.4500\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 188us/step - loss: 2.2238 - acc: 0.6625 - val_loss: 2.2252 - val_acc: 0.4500\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 2.0307 - acc: 0.6875 - val_loss: 2.0435 - val_acc: 0.4500\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 222us/step - loss: 1.8566 - acc: 0.7250 - val_loss: 1.8775 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 1.6989 - acc: 0.7250 - val_loss: 1.7327 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 196us/step - loss: 1.5622 - acc: 0.7500 - val_loss: 1.6001 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 199us/step - loss: 1.4367 - acc: 0.7750 - val_loss: 1.4886 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 1.3261 - acc: 0.8000 - val_loss: 1.3887 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 1.2284 - acc: 0.8125 - val_loss: 1.3013 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 203us/step - loss: 1.1412 - acc: 0.8000 - val_loss: 1.2227 - val_acc: 0.5500\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 199us/step - loss: 1.0637 - acc: 0.8125 - val_loss: 1.1557 - val_acc: 0.5500\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 169us/step - loss: 0.9954 - acc: 0.8000 - val_loss: 1.0998 - val_acc: 0.5500\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.9364 - acc: 0.8000 - val_loss: 1.0521 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 188us/step - loss: 0.8838 - acc: 0.8000 - val_loss: 1.0041 - val_acc: 0.5500\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 184us/step - loss: 0.8389 - acc: 0.8000 - val_loss: 0.9590 - val_acc: 0.5500\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.7969 - acc: 0.8250 - val_loss: 0.9239 - val_acc: 0.5500\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 176us/step - loss: 0.7616 - acc: 0.8250 - val_loss: 0.8917 - val_acc: 0.5500\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.7308 - acc: 0.8250 - val_loss: 0.8628 - val_acc: 0.5500\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.7037 - acc: 0.8375 - val_loss: 0.8362 - val_acc: 0.5500\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.6801 - acc: 0.8375 - val_loss: 0.8143 - val_acc: 0.5500\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 167us/step - loss: 0.6597 - acc: 0.8625 - val_loss: 0.7920 - val_acc: 0.6500\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.6435 - acc: 0.8875 - val_loss: 0.7742 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 192us/step - loss: 0.6280 - acc: 0.9125 - val_loss: 0.7642 - val_acc: 0.6500\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 198us/step - loss: 0.6145 - acc: 0.9125 - val_loss: 0.7575 - val_acc: 0.7000\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.6031 - acc: 0.8875 - val_loss: 0.7529 - val_acc: 0.6500\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5940 - acc: 0.8750 - val_loss: 0.7476 - val_acc: 0.6500\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5849 - acc: 0.8500 - val_loss: 0.7380 - val_acc: 0.6500\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.5777 - acc: 0.9000 - val_loss: 0.7289 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 202us/step - loss: 0.5713 - acc: 0.9250 - val_loss: 0.7230 - val_acc: 0.7000\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 186us/step - loss: 0.5662 - acc: 0.9250 - val_loss: 0.7199 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5618 - acc: 0.9250 - val_loss: 0.7148 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 165us/step - loss: 0.5576 - acc: 0.9250 - val_loss: 0.7126 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5544 - acc: 0.9250 - val_loss: 0.7113 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5514 - acc: 0.9250 - val_loss: 0.7118 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 180us/step - loss: 0.5490 - acc: 0.9000 - val_loss: 0.7155 - val_acc: 0.6500\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5476 - acc: 0.8500 - val_loss: 0.7164 - val_acc: 0.6500\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5464 - acc: 0.8500 - val_loss: 0.7161 - val_acc: 0.6500\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5452 - acc: 0.8375 - val_loss: 0.7113 - val_acc: 0.6500\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 211us/step - loss: 0.5436 - acc: 0.8750 - val_loss: 0.7048 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5419 - acc: 0.9125 - val_loss: 0.7005 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 177us/step - loss: 0.5407 - acc: 0.9375 - val_loss: 0.6976 - val_acc: 0.7500\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5399 - acc: 0.9375 - val_loss: 0.6970 - val_acc: 0.7500\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5397 - acc: 0.9375 - val_loss: 0.6979 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5388 - acc: 0.9375 - val_loss: 0.7008 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 176us/step - loss: 0.5384 - acc: 0.9250 - val_loss: 0.7025 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 191us/step - loss: 0.5379 - acc: 0.9125 - val_loss: 0.7011 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.5377 - acc: 0.9375 - val_loss: 0.7000 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 217us/step - loss: 0.5372 - acc: 0.9375 - val_loss: 0.7018 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5370 - acc: 0.9125 - val_loss: 0.7051 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 186us/step - loss: 0.5376 - acc: 0.9000 - val_loss: 0.7103 - val_acc: 0.6500\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5373 - acc: 0.8875 - val_loss: 0.7097 - val_acc: 0.6500\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 168us/step - loss: 0.5368 - acc: 0.9000 - val_loss: 0.7107 - val_acc: 0.7000\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5368 - acc: 0.9000 - val_loss: 0.7108 - val_acc: 0.7000\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5367 - acc: 0.9000 - val_loss: 0.7085 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5365 - acc: 0.9125 - val_loss: 0.7075 - val_acc: 0.7500\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.5362 - acc: 0.9125 - val_loss: 0.7063 - val_acc: 0.7500\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5360 - acc: 0.9125 - val_loss: 0.7047 - val_acc: 0.7500\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 164us/step - loss: 0.5367 - acc: 0.9250 - val_loss: 0.7015 - val_acc: 0.7500\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5364 - acc: 0.9250 - val_loss: 0.7026 - val_acc: 0.7500\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 137us/step - loss: 0.5359 - acc: 0.9250 - val_loss: 0.7016 - val_acc: 0.7500\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5358 - acc: 0.9250 - val_loss: 0.7012 - val_acc: 0.7500\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.5367 - acc: 0.9250 - val_loss: 0.6977 - val_acc: 0.7500\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5365 - acc: 0.9375 - val_loss: 0.6967 - val_acc: 0.7500\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5379 - acc: 0.9250 - val_loss: 0.7007 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5363 - acc: 0.9125 - val_loss: 0.6979 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5360 - acc: 0.9125 - val_loss: 0.6978 - val_acc: 0.7500\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5358 - acc: 0.9250 - val_loss: 0.6998 - val_acc: 0.7500\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5362 - acc: 0.9125 - val_loss: 0.7008 - val_acc: 0.7500\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5358 - acc: 0.9250 - val_loss: 0.7000 - val_acc: 0.7500\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 211us/step - loss: 0.5358 - acc: 0.9250 - val_loss: 0.7016 - val_acc: 0.7500\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5369 - acc: 0.9125 - val_loss: 0.7050 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5357 - acc: 0.9125 - val_loss: 0.7041 - val_acc: 0.7500\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5360 - acc: 0.9250 - val_loss: 0.7017 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5364 - acc: 0.9250 - val_loss: 0.7026 - val_acc: 0.7500\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5364 - acc: 0.9250 - val_loss: 0.6997 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 203us/step - loss: 0.5356 - acc: 0.9250 - val_loss: 0.7001 - val_acc: 0.7500\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5362 - acc: 0.9250 - val_loss: 0.7017 - val_acc: 0.7500\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 215us/step - loss: 0.5355 - acc: 0.9250 - val_loss: 0.7016 - val_acc: 0.7500\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.5356 - acc: 0.9250 - val_loss: 0.7002 - val_acc: 0.7500\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5360 - acc: 0.9250 - val_loss: 0.6988 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5359 - acc: 0.9250 - val_loss: 0.6974 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 176us/step - loss: 0.5364 - acc: 0.9250 - val_loss: 0.6970 - val_acc: 0.7500\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5364 - acc: 0.9250 - val_loss: 0.6949 - val_acc: 0.7500\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.5365 - acc: 0.9375 - val_loss: 0.6952 - val_acc: 0.7500\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5360 - acc: 0.9375 - val_loss: 0.6977 - val_acc: 0.7500\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5366 - acc: 0.9375 - val_loss: 0.7016 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5359 - acc: 0.9250 - val_loss: 0.7040 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5355 - acc: 0.9250 - val_loss: 0.7044 - val_acc: 0.7500\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 207us/step - loss: 0.5356 - acc: 0.9250 - val_loss: 0.7049 - val_acc: 0.7500\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5359 - acc: 0.9250 - val_loss: 0.7070 - val_acc: 0.7500\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5356 - acc: 0.9250 - val_loss: 0.7075 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5359 - acc: 0.9250 - val_loss: 0.7100 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5357 - acc: 0.9125 - val_loss: 0.7105 - val_acc: 0.7000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2,input_shape=(28*28,),kernel_regularizer=regularizers.l2(1)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X,Y,epochs=100,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  training  testing  baseline\n",
       "0      1    0.4625     0.35      0.58\n",
       "1      2    0.5500     0.40      0.58\n",
       "2      3    0.5750     0.45      0.58\n",
       "3      4    0.5750     0.50      0.58\n",
       "4      5    0.5750     0.50      0.58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = pd.DataFrame()\n",
    "accuracy['epoch'] = hist.epoch\n",
    "accuracy['epoch'] = accuracy['epoch']+1\n",
    "accuracy['training'] = hist.history['acc']\n",
    "accuracy['testing'] = hist.history['val_acc']\n",
    "accuracy['baseline'] = baseline\n",
    "accuracy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f50905f898>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = accuracy.plot.line(x='epoch',y='training')\n",
    "ax = accuracy.plot.line(x='epoch',y='testing',ax=ax)\n",
    "accuracy.plot.line(x='epoch',y='baseline',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the regulation value, the lower the training and testing accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
